{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ece72ee",
   "metadata": {},
   "source": [
    "### Python DataWrangling Pandas Combining\n",
    "\n",
    "_Combine DataFrames with .concat()_\n",
    "\n",
    "In this lesson, we'll return to the video game sales dataset. Here are the first few rows to remind you of its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1073676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name platform  year_of_release         genre publisher  \\\n",
      "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
      "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
      "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
      "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
      "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
      "\n",
      "  developer  na_sales  eu_sales  jp_sales  critic_score user_score  \n",
      "0  Nintendo     41.36     28.96      3.77          76.0          8  \n",
      "1       NaN     29.08      3.58      6.81           NaN        NaN  \n",
      "2  Nintendo     15.68     12.76      3.79          82.0        8.3  \n",
      "3  Nintendo     15.61     10.93      3.28          80.0          8  \n",
      "4       NaN     11.27      8.89     10.22           NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6720362e",
   "metadata": {},
   "source": [
    "We want to know some general statistics about game publishers, specifically:\n",
    "\n",
    "- their average review score;\n",
    "- their total sales.\n",
    "\n",
    "As we've already seen, we can do this using groupby(). First, let's get the average review score for each publisher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c0b242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publisher\n",
      "10TACLE Studios                 42.000000\n",
      "1C Company                      73.000000\n",
      "20th Century Fox Video Games          NaN\n",
      "2D Boy                          90.000000\n",
      "3DO                             57.470588\n",
      "                                  ...    \n",
      "id Software                     85.000000\n",
      "imageepoch Inc.                       NaN\n",
      "inXile Entertainment            81.000000\n",
      "mixi, Inc                             NaN\n",
      "responDESIGN                          NaN\n",
      "Name: critic_score, Length: 581, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_score = df.groupby('publisher')['critic_score'].mean()\n",
    "print(mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414afc07",
   "metadata": {},
   "source": [
    "Let's also get the number of sales. The easiest way to do this is with a second groupby():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d487c375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publisher\n",
      "10TACLE Studios                 0.11\n",
      "1C Company                      0.08\n",
      "20th Century Fox Video Games    1.92\n",
      "2D Boy                          0.03\n",
      "3DO                             9.52\n",
      "                                ... \n",
      "id Software                     0.02\n",
      "imageepoch Inc.                 0.04\n",
      "inXile Entertainment            0.09\n",
      "mixi, Inc                       0.87\n",
      "responDESIGN                    0.13\n",
      "Name: total_sales, Length: 581, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['total_sales'] = df['na_sales'] + df['eu_sales'] + df['jp_sales']\n",
    "num_sales = df.groupby('publisher')['total_sales'].sum()\n",
    "print(num_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3502e",
   "metadata": {},
   "source": [
    "Notice that the index for both results is the 'publisher' column _because we grouped by 'publisher' in both cases_. __Since both results share the same index, we can easily join the results__ into a DataFrame using pandas' concat() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab2f2cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              critic_score  total_sales\n",
      "publisher                                              \n",
      "10TACLE Studios                  42.000000         0.11\n",
      "1C Company                       73.000000         0.08\n",
      "20th Century Fox Video Games           NaN         1.92\n",
      "2D Boy                           90.000000         0.03\n",
      "3DO                              57.470588         9.52\n",
      "...                                    ...          ...\n",
      "id Software                      85.000000         0.02\n",
      "imageepoch Inc.                        NaN         0.04\n",
      "inXile Entertainment             81.000000         0.09\n",
      "mixi, Inc                              NaN         0.87\n",
      "responDESIGN                           NaN         0.13\n",
      "\n",
      "[581 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_concat = pd.concat([mean_score, num_sales], axis='columns')\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efa189",
   "metadata": {},
   "source": [
    "In general, concat() expects a list of Series and/or DataFrame objects. To get our result, we passed a list of Series variables to concat() and set axis='columns' to ensure they were combined as columns.\n",
    "\n",
    "Note that the original column names are preserved in the concatenated DataFrame.\n",
    "\n",
    "We can rename columns using the columns method. It can be called on a DataFrame and passed a list of new column names to replace the existing ones. The new names must be passed in the same order as the original column names.\n",
    "\n",
    "Let's rename 'critic_score', as it now represents an average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c50ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              avg_critic_score  total_sales\n",
      "publisher                                                  \n",
      "10TACLE Studios                      42.000000         0.11\n",
      "1C Company                           73.000000         0.08\n",
      "20th Century Fox Video Games               NaN         1.92\n",
      "2D Boy                               90.000000         0.03\n",
      "3DO                                  57.470588         9.52\n",
      "...                                        ...          ...\n",
      "id Software                          85.000000         0.02\n",
      "imageepoch Inc.                            NaN         0.04\n",
      "inXile Entertainment                 81.000000         0.09\n",
      "mixi, Inc                                  NaN         0.87\n",
      "responDESIGN                               NaN         0.13\n",
      "\n",
      "[581 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_concat.columns = ['avg_critic_score', 'total_sales']\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21afeee",
   "metadata": {},
   "source": [
    "In general, it's a good idea to rename columns after grouping and processing to give a more indicative representation of how the columns were processed.\n",
    "\n",
    "You may have noticed that we could get the same result as before using agg(). However, concat() is quite versatile. We can use it to concatenate DataFrames:\n",
    "\n",
    "- by rows, assuming they have the same number of columns;\n",
    "\n",
    "- by columns if they have the same number of rows.\n",
    "\n",
    "To concatenate rows from separate DataFrames, we can use concat() and set axis='index' (or omit this parameter, as axis='index' is the default argument). Alternatively, we can use integers for the index= argument, where index=0 will concatenate rows and index=1 will concatenate columns.\n",
    "\n",
    "Here's an example where we filter the data in two separate DataFrames based on gender and then recombine them into a single DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9243561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   name         genre\n",
      "4                              Pokemon Red/Pokemon Blue  Role-Playing\n",
      "12                          Pokemon Gold/Pokemon Silver  Role-Playing\n",
      "20                        Pokemon Diamond/Pokemon Pearl  Role-Playing\n",
      "25                        Pokemon Ruby/Pokemon Sapphire  Role-Playing\n",
      "27                          Pokemon Black/Pokemon White  Role-Playing\n",
      "...                                                 ...           ...\n",
      "16356                                    Strider (2014)      Platform\n",
      "16358                                Goku Makaimura Kai      Platform\n",
      "16603  The Land Before Time: Into the Mysterious Beyond      Platform\n",
      "16710                Woody Woodpecker in Crazy Castle 5      Platform\n",
      "16715                                  Spirits & Spells      Platform\n",
      "\n",
      "[2388 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "rpgs = df[df['genre'] == 'Role-Playing']\n",
    "platformers = df[df['genre'] == 'Platform']\n",
    "\n",
    "df_concat = pd.concat([rpgs, platformers])\n",
    "print(df_concat[['name', 'genre']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9379d",
   "metadata": {},
   "source": [
    "And so two DataFrames are merged into one! Remember, __this works here because both smaller DataFrames have the same columns__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96b50f",
   "metadata": {},
   "source": [
    "##### __Excercise 01__\n",
    "\n",
    "We read the data, created a 'total_sales' column, and calculated the total sales for each platform in the total_sales variable.\n",
    "\n",
    "You need to calculate the total number of publishers that created a game on each platform using nunique(). Assign the result to a variable called num_pubs and then display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e374542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform\n",
      "2600      96.07\n",
      "3DO        0.10\n",
      "3DS      245.64\n",
      "DC        15.68\n",
      "DS       747.13\n",
      "GB       247.26\n",
      "GBA      310.12\n",
      "GC       193.75\n",
      "GEN       27.46\n",
      "GG         0.04\n",
      "N64      214.30\n",
      "NES      245.74\n",
      "NG         1.44\n",
      "PC       237.14\n",
      "PCFX       0.03\n",
      "PS       689.95\n",
      "PS2     1062.33\n",
      "PS3      803.97\n",
      "PS4      265.83\n",
      "PSP      252.63\n",
      "PSV       47.63\n",
      "SAT       33.52\n",
      "SCD        1.81\n",
      "SNES     196.82\n",
      "TG16       0.16\n",
      "WS         1.42\n",
      "Wii      828.44\n",
      "WiiU      76.24\n",
      "X360     885.66\n",
      "XB       249.02\n",
      "XOne     145.05\n",
      "Name: total_sales, dtype: float64\n",
      "\n",
      "platform\n",
      "2600     26\n",
      "3DO       3\n",
      "3DS      82\n",
      "DC       15\n",
      "DS      175\n",
      "GB       17\n",
      "GBA      87\n",
      "GC       52\n",
      "GEN       7\n",
      "GG        1\n",
      "N64      54\n",
      "NES      12\n",
      "NG        3\n",
      "PC      133\n",
      "PCFX      1\n",
      "PS      151\n",
      "PS2     172\n",
      "PS3     103\n",
      "PS4      75\n",
      "PSP     127\n",
      "PSV      66\n",
      "SAT      44\n",
      "SCD       1\n",
      "SNES     50\n",
      "TG16      2\n",
      "WS        2\n",
      "Wii     113\n",
      "WiiU     23\n",
      "X360    102\n",
      "XB       73\n",
      "XOne     46\n",
      "Name: publisher, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "df['total_sales'] = df['na_sales'] + df['eu_sales'] + df['jp_sales']\n",
    "\n",
    "total_sales = df.groupby('platform')['total_sales'].sum()\n",
    "\n",
    "num_pubs =  df.groupby('platform')['publisher'].nunique()\n",
    "print(total_sales)\n",
    "print()\n",
    "print(num_pubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a93e2ee",
   "metadata": {},
   "source": [
    "Combine total_sales and num_pubs columns into a DataFrame named platforms using concat(). Change the column names in platforms to 'total_sales' and 'num_publishers', respectively, then print platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dab7fe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          total_sales  num_publishers\n",
      "platform                             \n",
      "2600            96.07              26\n",
      "3DO              0.10               3\n",
      "3DS            245.64              82\n",
      "DC              15.68              15\n",
      "DS             747.13             175\n",
      "GB             247.26              17\n",
      "GBA            310.12              87\n",
      "GC             193.75              52\n",
      "GEN             27.46               7\n",
      "GG               0.04               1\n",
      "N64            214.30              54\n",
      "NES            245.74              12\n",
      "NG               1.44               3\n",
      "PC             237.14             133\n",
      "PCFX             0.03               1\n",
      "PS             689.95             151\n",
      "PS2           1062.33             172\n",
      "PS3            803.97             103\n",
      "PS4            265.83              75\n",
      "PSP            252.63             127\n",
      "PSV             47.63              66\n",
      "SAT             33.52              44\n",
      "SCD              1.81               1\n",
      "SNES           196.82              50\n",
      "TG16             0.16               2\n",
      "WS               1.42               2\n",
      "Wii            828.44             113\n",
      "WiiU            76.24              23\n",
      "X360           885.66             102\n",
      "XB             249.02              73\n",
      "XOne           145.05              46\n"
     ]
    }
   ],
   "source": [
    "platforms = pd.concat([total_sales, num_pubs], axis='columns')\n",
    "platforms.columns = ['total_sales', 'num_publishers']\n",
    "print(platforms[['total_sales', 'num_publishers']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc79d94",
   "metadata": {},
   "source": [
    "##### _Merging DataFrames with merge()_\n",
    "\n",
    "You've just learned how to combine DataFrames by concatenating them by row or column using concat().\n",
    "\n",
    "Concatenating DataFrames preserves the total amount of data. For example, merging a DataFrame that has two columns and three rows with another DataFrame that has the same two columns and five rows results in a DataFrame with two columns and eight rows. The total number of cells before and after concatenation is sixteen.\n",
    "\n",
    "Now you'll learn how to merge DataFrames using the merge() method in a way that affects the amount of data you're working with.\n",
    "\n",
    "Consider the following example: two literature students agree that one will write half of the summer reading list on the board while the other watches YouTube. Then, the first will go to the cafeteria, while the second copies the rest of the list. Finally, the two will merge the lists. Teamwork! Let's see how it went:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7584b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       author                         title\n",
      "0      Alcott                  Little Women\n",
      "1  Fitzgerald              The Great Gatsby\n",
      "2   Steinbeck               Of Mice and Men\n",
      "3       Twain  The Adventures of Tom Sawyer\n",
      "4   Hemingway       The Old Man and the Sea\n",
      "\n",
      "      author                               title\n",
      "0  Steinbeck                        East of Eden\n",
      "1      Twain  The Adventures of Huckleberry Finn\n",
      "2  Hemingway             For Whom the Bell Tolls\n",
      "3   Salinger              The Catcher in the Rye\n",
      "4  Hawthorne                 The Scarlett Letter\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "first_pupil_df = pd.DataFrame(\n",
    "    {\n",
    "        'author': ['Alcott', 'Fitzgerald', 'Steinbeck', 'Twain', 'Hemingway'],\n",
    "        'title': ['Little Women',\n",
    "                  'The Great Gatsby',\n",
    "                  'Of Mice and Men',\n",
    "                  'The Adventures of Tom Sawyer',\n",
    "                  'The Old Man and the Sea'\n",
    "                 ],\n",
    "    }\n",
    ")\n",
    "second_pupil_df = pd.DataFrame(\n",
    "    {\n",
    "        'author': ['Steinbeck', 'Twain', 'Hemingway', 'Salinger', 'Hawthorne'],\n",
    "        'title': ['East of Eden',\n",
    "                  'The Adventures of Huckleberry Finn',\n",
    "                  'For Whom the Bell Tolls',\n",
    "                  'The Catcher in the Rye',\n",
    "                  'The Scarlett Letter'\n",
    "                 ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(first_pupil_df)\n",
    "print()\n",
    "print(second_pupil_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8873e6bf",
   "metadata": {},
   "source": [
    "##### _Inner Join_\n",
    "\n",
    "Let's use the merge() method to combine entries with the same authors. The name of the column to be merged is passed to the on= parameter, in this case, 'author':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5224ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      author                       title_x                             title_y\n",
      "0  Steinbeck               Of Mice and Men                        East of Eden\n",
      "1      Twain  The Adventures of Tom Sawyer  The Adventures of Huckleberry Finn\n",
      "2  Hemingway       The Old Man and the Sea             For Whom the Bell Tolls\n"
     ]
    }
   ],
   "source": [
    "both_pupils = first_pupil_df.merge(second_pupil_df, on='author')\n",
    "print(both_pupils) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af789f45",
   "metadata": {},
   "source": [
    "The result contains only those authors present in both original DataFrames.\n",
    "\n",
    "The merged DataFrame includes all columns from the original DataFrames, but only the rows with shared authors are retained. Since both original DataFrames have a column named 'title', pandas added the suffixes _x and _y to differentiate them in the merged DataFrame. It's worth noting that the merged DataFrame only has 9 cells, compared to 20 cells in the original DataFrames: the amount of data has changed!\n",
    "\n",
    "This way of merging is called an inner merge. There are other types of merges, which can be specified with the how= parameter of merge(). But 'inner' is the default argument to how=, so we don't need to include it above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f0175",
   "metadata": {},
   "source": [
    "##### _Outer join_\n",
    "\n",
    "An outer join (merge) differs from an inner join in that all values ​​in the specified column are retained from both original DataFrames, but the merged DataFrame has missing values ​​where there is no match. This is best illustrated with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9b104ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       author                       title_x  \\\n",
      "0      Alcott                  Little Women   \n",
      "1  Fitzgerald              The Great Gatsby   \n",
      "2   Hawthorne                           NaN   \n",
      "3   Hemingway       The Old Man and the Sea   \n",
      "4    Salinger                           NaN   \n",
      "5   Steinbeck               Of Mice and Men   \n",
      "6       Twain  The Adventures of Tom Sawyer   \n",
      "\n",
      "                              title_y  \n",
      "0                                 NaN  \n",
      "1                                 NaN  \n",
      "2                 The Scarlett Letter  \n",
      "3             For Whom the Bell Tolls  \n",
      "4              The Catcher in the Rye  \n",
      "5                        East of Eden  \n",
      "6  The Adventures of Huckleberry Finn  \n"
     ]
    }
   ],
   "source": [
    "both_pupils = first_pupil_df.merge(second_pupil_df, on='author', how='outer')\n",
    "print(both_pupils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e08574",
   "metadata": {},
   "source": [
    "There are 7 unique authors in both original DataFrames, each represented by a row in the merged DataFrame. For authors in the first DataFrame who are not also in the second (i.e., 'Alcott' and 'Fitzgerald'), there are NaN values ​​in the column that comes from the second DataFrame (i.e., 'title_y'), and vice versa. Also, notice that we now have 21 data cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e136c3",
   "metadata": {},
   "source": [
    "##### _Left join_\n",
    "\n",
    "The last type of join we'd like to discuss is the left join (left merge), which we can perform by passing how='left' to merge(). In a left join, all values ​​from the left DataFrame (the one we call merge() on) are present in the merged DataFrame. Values ​​from the right DataFrame (the one we pass as input to merge()) are only retained for values ​​that match the specified column in the left DataFrame. Again, this is best explained with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb888483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       author                       title_x  \\\n",
      "0      Alcott                  Little Women   \n",
      "1  Fitzgerald              The Great Gatsby   \n",
      "2   Steinbeck               Of Mice and Men   \n",
      "3       Twain  The Adventures of Tom Sawyer   \n",
      "4   Hemingway       The Old Man and the Sea   \n",
      "\n",
      "                              title_y  \n",
      "0                                 NaN  \n",
      "1                                 NaN  \n",
      "2                        East of Eden  \n",
      "3  The Adventures of Huckleberry Finn  \n",
      "4             For Whom the Bell Tolls  \n"
     ]
    }
   ],
   "source": [
    "both_pupils = first_pupil_df.merge(second_pupil_df, on='author', how='left')\n",
    "print(both_pupils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e830b",
   "metadata": {},
   "source": [
    "As you can see, all of the first student's authors and titles are in the merged DataFrame, but the second student's rows with 'Salinger' and 'Hawthorne' are not because those authors don't appear in the first student's DataFrame.\n",
    "\n",
    "This left join contains 15 cells of data, which differ from the original number and amounts in each of the other joins we performed.\n",
    "\n",
    "Note that there is also a right join (how='right'). However, it works identically to a left join, except that the merged DataFrame retains all the values ​​from the right DataFrame instead of the left. The same result can be achieved by performing a left join and changing the order of the DataFrames.\n",
    "\n",
    "Here's a Venn diagram illustrating all the merge options we've discussed, to make it even easier to understand:\n",
    "\n",
    "![Alt Text](Pics/merge.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca64694",
   "metadata": {},
   "source": [
    "Consider the Column Names\n",
    "\n",
    "There are two aspects of all the joins performed so far that we need to address:\n",
    "\n",
    "- The merged DataFrame has the suffixes _x and _y appended to the 'title' column names.\n",
    "\n",
    "- The column we are joining on has the same name in both DataFrames, 'author'.\n",
    "\n",
    "When merging DataFrames in pandas, it is important to ensure that no two columns have the same name. Otherwise, pandas will automatically add the suffixes _x and _y. However, these suffixes are not very descriptive. To set better suffixes, pass a tuple of suffixes to the suffixes= parameter in merge():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a8f7a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      author             title_1st_student                   title_2nd_student\n",
      "0  Steinbeck               Of Mice and Men                        East of Eden\n",
      "1      Twain  The Adventures of Tom Sawyer  The Adventures of Huckleberry Finn\n",
      "2  Hemingway       The Old Man and the Sea             For Whom the Bell Tolls\n"
     ]
    }
   ],
   "source": [
    "both_pupils = first_pupil_df.merge(second_pupil_df, on='author', suffixes=('_1st_student', '_2nd_student')\n",
    "                                  )\n",
    "print(both_pupils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6bedbb",
   "metadata": {},
   "source": [
    "##### _Excercise 01_\n",
    "\n",
    "We have two DataFrames, df_orders and df_members, which have already been included in the precode.\n",
    "\n",
    "- df_orders:\n",
    "* Each row represents a single order.\n",
    "* Contains a column named 'user_id' that indicates which customer placed the order.\n",
    "* Contains an 'id' column that identifies each order.\n",
    "\n",
    "- df_members:\n",
    "* Each row represents a single customer.\n",
    "* Contains an 'id' column that identifies each customer.\n",
    "\n",
    "Your task:\n",
    "\n",
    "Merge these two DataFrames so that the resulting DataFrame includes only those customers who have placed an order. Follow these steps:\n",
    "\n",
    "- Merge type:\n",
    "* Choose a merge that retains only customers with matching orders (for example, an inner merge).\n",
    "- Merge details:\n",
    "* Use df_members as the left DataFrame and match the customer id.\n",
    "* Use df_orders as the right DataFrame and match the 'user_id' column (not the order_id).\n",
    "- Column Suffixes:\n",
    "* Apply suffixes to overlapping column names: add '_member' to the columns in df_members and '_order' to the columns in df_orders.\n",
    "- Store and Display:\n",
    "* Assign the merged DataFrame to a variable named df_merged.\n",
    "* Display df_merged to review the results.\n",
    "\n",
    "Note:\n",
    "Do not delete any columns during the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7784fd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id       username date_joined\n",
      "0  9832  monkeycool447  2021-06-19\n",
      "1  9833      Appl3Girl  2021-06-19\n",
      "2  9834       hiiml00t  2021-06-19\n",
      "3  9835       jd663366  2021-06-19\n",
      "4  9836   watermelon89  2021-06-19\n",
      "5  9837        SUPERXD  2021-06-19\n",
      "6  9838    aasmith0909  2021-06-19\n",
      "7  9839     NotHotDog2  2021-06-20\n",
      "8  9840       starrats  2021-06-20\n",
      "9  9841      beat1box2  2021-06-20\n",
      "\n",
      "           id  user_id    service_id      order_timestamp\n",
      "0   163548290     9836  XMD8nVShpINn  2021-06-22Z18:32:59\n",
      "1   163548291     9836  PXAQ9MiP7BvW  2021-06-22Z18:32:59\n",
      "2   163548292     8725  ikNjwXadFlDy  2021-06-22Z18:33:19\n",
      "3   163548293     9840  9KyrlovWf2nH  2021-06-22Z18:34:00\n",
      "4   163548294     9121  WXoCdFvGgXmb  2021-06-22Z18:35:16\n",
      "5   163548295     9121  idVIMieuoAMU  2021-06-22Z18:35:16\n",
      "6   163548296     9121  CC4F1NgnYGs3  2021-06-22Z18:35:16\n",
      "7   163548297     9839  NvwWjzW7FydE  2021-06-22Z18:36:21\n",
      "8   163548298     9841  fCobsButtJD7  2021-06-22Z18:36:55\n",
      "9   163548299     9837  R2GA1xIVXK1o  2021-06-22Z18:39:12\n",
      "10  163548300     6674  aVFRDibsnP6H  2021-06-22Z18:42:36\n",
      "11  163548301     6674  Yr52FZCJxmxk  2021-06-22Z18:42:36\n",
      "\n",
      "   id_members      username date_joined  id_orders  user_id    service_id  \\\n",
      "0        9836  watermelon89  2021-06-19  163548290     9836  XMD8nVShpINn   \n",
      "1        9836  watermelon89  2021-06-19  163548291     9836  PXAQ9MiP7BvW   \n",
      "2        9837       SUPERXD  2021-06-19  163548299     9837  R2GA1xIVXK1o   \n",
      "3        9839    NotHotDog2  2021-06-20  163548297     9839  NvwWjzW7FydE   \n",
      "4        9840      starrats  2021-06-20  163548293     9840  9KyrlovWf2nH   \n",
      "5        9841     beat1box2  2021-06-20  163548298     9841  fCobsButtJD7   \n",
      "\n",
      "       order_timestamp  \n",
      "0  2021-06-22Z18:32:59  \n",
      "1  2021-06-22Z18:32:59  \n",
      "2  2021-06-22Z18:39:12  \n",
      "3  2021-06-22Z18:36:21  \n",
      "4  2021-06-22Z18:34:00  \n",
      "5  2021-06-22Z18:36:55  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_members = pd.read_csv('DataSets/new_members.csv')\n",
    "df_orders  = pd.read_csv('DataSets/recent_orders.csv')\n",
    "\n",
    "print(df_members)\n",
    "print()\n",
    "print(df_orders)\n",
    "print()\n",
    "\n",
    "df_merged = df_members.merge(df_orders, left_on='id', right_on='user_id', how='inner', suffixes=('_members', '_orders'))\n",
    "\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf61a27",
   "metadata": {},
   "source": [
    "Let's tidy things up a bit.\n",
    "\n",
    "- Remove the duplicate column (in this case, 'user_id').\n",
    "- Assign the result back to the 'df_merged' DataFrame.\n",
    "- Display the merged DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cde26d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_members      username date_joined  id_orders    service_id  \\\n",
      "0        9836  watermelon89  2021-06-19  163548290  XMD8nVShpINn   \n",
      "1        9836  watermelon89  2021-06-19  163548291  PXAQ9MiP7BvW   \n",
      "2        9837       SUPERXD  2021-06-19  163548299  R2GA1xIVXK1o   \n",
      "3        9839    NotHotDog2  2021-06-20  163548297  NvwWjzW7FydE   \n",
      "4        9840      starrats  2021-06-20  163548293  9KyrlovWf2nH   \n",
      "5        9841     beat1box2  2021-06-20  163548298  fCobsButtJD7   \n",
      "\n",
      "       order_timestamp  \n",
      "0  2021-06-22Z18:32:59  \n",
      "1  2021-06-22Z18:32:59  \n",
      "2  2021-06-22Z18:39:12  \n",
      "3  2021-06-22Z18:36:21  \n",
      "4  2021-06-22Z18:34:00  \n",
      "5  2021-06-22Z18:36:55  \n"
     ]
    }
   ],
   "source": [
    "df_merged = df_merged.drop(labels='user_id', axis='columns') \n",
    "print(df_merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Win11_Python-PipVenv-Github-Hmb7GD39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
