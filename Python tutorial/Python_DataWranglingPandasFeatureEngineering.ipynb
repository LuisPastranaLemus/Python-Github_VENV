{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1eaac1b",
   "metadata": {},
   "source": [
    "### __Python DataWranglingPandasFeatureEngineering__\n",
    "\n",
    "Feature Engineering is a crucial step in data analysis, machine learning, and data science. It involves:\n",
    "\n",
    "- Creating new features from existing data,\n",
    "\n",
    "- Transforming variables to better represent the underlying problem,\n",
    "\n",
    "- Encoding categorical variables, scaling numeric data, or deriving time-based features,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a7e07",
   "metadata": {},
   "source": [
    "##### _Create new columns based on values ​​from others_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a7cdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name platform  year_of_release         genre publisher  \\\n",
      "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
      "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
      "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
      "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
      "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
      "\n",
      "  developer  na_sales  eu_sales  jp_sales  critic_score user_score  \n",
      "0  Nintendo     41.36     28.96      3.77          76.0          8  \n",
      "1       NaN     29.08      3.58      6.81           NaN        NaN  \n",
      "2  Nintendo     15.68     12.76      3.79          82.0        8.3  \n",
      "3  Nintendo     15.61     10.93      3.28          80.0          8  \n",
      "4       NaN     11.27      8.89     10.22           NaN        NaN  \n",
      "\n",
      "Index(['name', 'platform', 'year_of_release', 'genre', 'publisher',\n",
      "       'developer', 'na_sales', 'eu_sales', 'jp_sales', 'critic_score',\n",
      "       'user_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "print(df.head())\n",
    "print()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b7260",
   "metadata": {},
   "source": [
    "Notice that the DataFrame above includes sales from three regions: NA (North America), EU (Europe), and Japan (JPN). To create a column called 'total_sales', we need to generate it from the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae044d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    74.09\n",
      "1    39.47\n",
      "2    32.23\n",
      "3    29.82\n",
      "4    30.38\n",
      "Name: total_sales, dtype: float64\n",
      "\n",
      "Index(['name', 'platform', 'year_of_release', 'genre', 'publisher',\n",
      "       'developer', 'na_sales', 'eu_sales', 'jp_sales', 'critic_score',\n",
      "       'user_score', 'total_sales'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "\n",
    "df['total_sales'] = df['na_sales'] + df['eu_sales'] + df['jp_sales']\n",
    "print(df['total_sales'].head())\n",
    "print()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1200c60",
   "metadata": {},
   "source": [
    "This works because most mathematical functions work in a vector-based manner: they are applied to entire columns at once, rather than looping through each value in a column. This provides more efficient and concise code.\n",
    "\n",
    "With this simple code, you can create a new column called 'total_sales' in the DataFrame. The contents of this column will consist of the sum of sales in the three regions, line by line.\n",
    "\n",
    "We can leverage this method to create columns from useful formulas. For example, if we want to calculate the portion of total sales that comes from the EU, we can do so like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4e2d08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.390876\n",
      "1    0.090702\n",
      "2    0.395904\n",
      "3    0.366533\n",
      "4    0.292627\n",
      "Name: eu_sales_share, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['eu_sales_share'] = df['eu_sales'] / df['total_sales']\n",
    "print(df['eu_sales_share'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f110a880",
   "metadata": {},
   "source": [
    "##### _Generate Boolean columns_\n",
    "\n",
    "Imagine we want a column to indicate whether something is true. We can create it using the comparison operators ==, <, >=, etc. For example, let's create a column that checks whether the publisher is Nintendo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8503beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    True\n",
      "1    True\n",
      "2    True\n",
      "3    True\n",
      "4    True\n",
      "Name: is_nintendo, dtype: bool\n",
      "\n",
      "Index(['name', 'platform', 'year_of_release', 'genre', 'publisher',\n",
      "       'developer', 'na_sales', 'eu_sales', 'jp_sales', 'critic_score',\n",
      "       'user_score', 'is_nintendo'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "\n",
    "# crear la columna is_nintendo y rellenarla\n",
    "df['is_nintendo'] = df['publisher'] == 'Nintendo'\n",
    "print(df['is_nintendo'].head())\n",
    "print()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf396f4",
   "metadata": {},
   "source": [
    "Remember that we can also do this with the convenient isin() method, which checks if a value is in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53aaef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                name platform  year_of_release         genre  \\\n",
      "0                         Wii Sports      Wii           2006.0        Sports   \n",
      "1                  Super Mario Bros.      NES           1985.0      Platform   \n",
      "2                     Mario Kart Wii      Wii           2008.0        Racing   \n",
      "3                  Wii Sports Resort      Wii           2009.0        Sports   \n",
      "4           Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing   \n",
      "...                              ...      ...              ...           ...   \n",
      "16712  Samurai Warriors: Sanada Maru      PS3           2016.0        Action   \n",
      "16713               LMA Manager 2007     X360           2006.0        Sports   \n",
      "16714        Haitaka no Psychedelica      PSV           2016.0     Adventure   \n",
      "16715               Spirits & Spells      GBA           2003.0      Platform   \n",
      "16716            Winning Post 8 2016      PSV           2016.0    Simulation   \n",
      "\n",
      "          publisher developer  na_sales  eu_sales  jp_sales  critic_score  \\\n",
      "0          Nintendo  Nintendo     41.36     28.96      3.77          76.0   \n",
      "1          Nintendo       NaN     29.08      3.58      6.81           NaN   \n",
      "2          Nintendo  Nintendo     15.68     12.76      3.79          82.0   \n",
      "3          Nintendo  Nintendo     15.61     10.93      3.28          80.0   \n",
      "4          Nintendo       NaN     11.27      8.89     10.22           NaN   \n",
      "...             ...       ...       ...       ...       ...           ...   \n",
      "16712    Tecmo Koei       NaN      0.00      0.00      0.01           NaN   \n",
      "16713   Codemasters       NaN      0.00      0.01      0.00           NaN   \n",
      "16714  Idea Factory       NaN      0.00      0.00      0.01           NaN   \n",
      "16715       Wanadoo       NaN      0.01      0.00      0.00           NaN   \n",
      "16716    Tecmo Koei       NaN      0.00      0.00      0.01           NaN   \n",
      "\n",
      "      user_score  \n",
      "0              8  \n",
      "1            NaN  \n",
      "2            8.3  \n",
      "3              8  \n",
      "4            NaN  \n",
      "...          ...  \n",
      "16712        NaN  \n",
      "16713        NaN  \n",
      "16714        NaN  \n",
      "16715        NaN  \n",
      "16716        NaN  \n",
      "\n",
      "[16717 rows x 11 columns]\n",
      "\n",
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "Name: platform, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "print(df)\n",
    "print()\n",
    "# asegúrate de que estés comparando minúsculas\n",
    "print(df['platform'].str.lower().isin(['gb', 'wii']).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd1b58",
   "metadata": {},
   "source": [
    "##### _Categorical columns_\n",
    "\n",
    "Working with raw string data rarely helps with data analysis, as string columns usually require some sort of processing.\n",
    "\n",
    "If the string column represents a set of categories, it's much better to treat those values ​​directly as categories.\n",
    "\n",
    "By converting a column to a categorical data type instead of leaving it as a string, we can save memory and speed up analysis, especially for large data sets. Categorical columns only store a single number (the category ID) for each entry, rather than the full text of the entry. Additionally, using categories can facilitate certain analyses, such as grouping data by category or filtering data based on multiple categories at once. This can be done with the categorical data type.\n",
    "\n",
    "Look at the unique values ​​in the 'platform' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd2baec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wii' 'NES' 'GB' 'DS' 'X360' 'PS3' 'PS2' 'SNES' 'GBA' 'PS4' '3DS' 'N64'\n",
      " 'PS' 'XB' 'PC' '2600' 'PSP' 'XOne' 'WiiU' 'GC' 'GEN' 'DC' 'PSV' 'SAT'\n",
      " 'SCD' 'WS' 'NG' 'TG16' '3DO' 'GG' 'PCFX']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "\n",
    "print(df['platform'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43538748",
   "metadata": {},
   "source": [
    "We can convert 'platform' from a string column to a categorical column using the astype() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9698158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Wii\n",
      "1    NES\n",
      "2    Wii\n",
      "3    Wii\n",
      "4     GB\n",
      "Name: platform, dtype: category\n",
      "Categories (31, object): ['2600', '3DO', '3DS', 'DC', ..., 'WiiU', 'X360', 'XB', 'XOne']\n"
     ]
    }
   ],
   "source": [
    "df['platform'] = df['platform'].astype('category')\n",
    "print(df['platform'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33b9e3",
   "metadata": {},
   "source": [
    "Notice that there are only 31 categories, even though there are 16,719 entries. When the column is stored as strings, we need to retain the full text of all 16,719 entries. __When stored as a category, we only store one number: the category ID__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f669bbba",
   "metadata": {},
   "source": [
    "##### _Example_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76302770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name platform  year_of_release         genre publisher  \\\n",
      "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
      "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
      "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
      "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
      "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
      "\n",
      "  developer  na_sales  eu_sales  jp_sales  critic_score user_score  \\\n",
      "0  Nintendo     41.36     28.96      3.77          76.0          8   \n",
      "1       NaN     29.08      3.58      6.81           NaN        NaN   \n",
      "2  Nintendo     15.68     12.76      3.79          82.0        8.3   \n",
      "4       NaN     11.27      8.89     10.22           NaN        NaN   \n",
      "3  Nintendo     15.61     10.93      3.28          80.0          8   \n",
      "\n",
      "   average_sales  \n",
      "0      24.696667  \n",
      "1      13.156667  \n",
      "2      10.743333  \n",
      "4      10.126667  \n",
      "3       9.940000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "\n",
    "df['average_sales'] = df[['jp_sales', 'na_sales', 'eu_sales']].mean(axis=1)\n",
    "\n",
    "df= df.sort_values(by='average_sales', ascending=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee8b8f",
   "metadata": {},
   "source": [
    "##### __Creating categorical columns__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a66027d",
   "metadata": {},
   "source": [
    "In the previous lesson, you learned how to create new numeric columns from calculations performed on other numeric columns in the data. In this lesson, you'll learn how to create new categorical columns that summarize numeric data in other columns. This technique can often simplify your analysis and make it easier for others to understand your results.\n",
    "\n",
    "Let's take another look at the 'year_of_release' column in the video game dataset. In particular, we want to know the range of years our data covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcbc35b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980.0 2020.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "\n",
    "print(df['year_of_release'].min(), df['year_of_release'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62188df7",
   "metadata": {},
   "source": [
    "Let's take a closer look at these values ​​by counting how many games we have per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbab91ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year_of_release\n",
      "2008.0    1427\n",
      "2009.0    1426\n",
      "2010.0    1255\n",
      "2007.0    1197\n",
      "2011.0    1136\n",
      "2006.0    1006\n",
      "2005.0     939\n",
      "2002.0     829\n",
      "2003.0     775\n",
      "2004.0     762\n",
      "2012.0     653\n",
      "2015.0     606\n",
      "2014.0     581\n",
      "2013.0     544\n",
      "2016.0     502\n",
      "2001.0     482\n",
      "1998.0     379\n",
      "2000.0     350\n",
      "1999.0     338\n",
      "1997.0     289\n",
      "1996.0     263\n",
      "1995.0     219\n",
      "1994.0     121\n",
      "1993.0      60\n",
      "1981.0      46\n",
      "1992.0      43\n",
      "1991.0      41\n",
      "1982.0      36\n",
      "1986.0      21\n",
      "1989.0      17\n",
      "1983.0      17\n",
      "1987.0      16\n",
      "1990.0      16\n",
      "1988.0      15\n",
      "1985.0      14\n",
      "1984.0      14\n",
      "1980.0       9\n",
      "2017.0       3\n",
      "2020.0       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_year_of_release = df['year_of_release'].value_counts()\n",
    "\n",
    "print(df_year_of_release)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c2399",
   "metadata": {},
   "source": [
    "We've received the response, but it's not sorted correctly. We need to sort it. The value_counts() method returns a count of the years, where years are the index of the new DataFrame and counts are the values. Therefore, we'll sort our result by the index values ​​to display it in chronological order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b304ae6f",
   "metadata": {},
   "source": [
    "##### __.sort_index()__\n",
    "\n",
    "The sort_index() method sorts the DataFrame by the index.\n",
    "\n",
    "_dataframe.sort_index(axis, level, ascending, inplace, kind, na_position, sort_remaining, ignore_index, key)_\n",
    "\n",
    "_axis_\t0 1 'index' 'columns'\tOptional. Default 0. Specifies the axis to sort by\n",
    "\n",
    "_level_\tString Number List of Strings/Numbers\tOptional. Default None. Specifies the index level to sort on\n",
    "\n",
    "_ascending_\tTrue False\tOptional, default True. Specifies whether to sort ascending (0 -> 9) or descending (9 -> 0)\n",
    "\n",
    "_inplace_\tTrue False\tOptional, default False. Specifies whether to perform the operation on the original DataFrame or not, if not, which is default, this method returns a new DataFrame\n",
    "\n",
    "_kind_\t'quicksort' 'mergesort' 'heapsort'\tOptional, default 'quicksort'. Specifies the sorting algorithm\n",
    "\n",
    "_na_position_\t'first' 'last'\tOptional, default 'last'. Specifies how to handle NULL values. 'first' means put them first, 'last' means put them last.\n",
    "\n",
    "_sort_remaining_\tTrue False\tOptional, default True. Specifies whether to sort by other levels as well, or not\n",
    "\n",
    "_ignore_index_\tTrue False\tOptional, default False. Specifies whether to ignore index or not. If True the original indexes are ignored, and replaced by 0, 1, 2 etc.\n",
    "\n",
    "_key_\tFunction\tOptional, specify a function to be executed before the sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "424987f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year_of_release\n",
      "1980.0       9\n",
      "1981.0      46\n",
      "1982.0      36\n",
      "1983.0      17\n",
      "1984.0      14\n",
      "1985.0      14\n",
      "1986.0      21\n",
      "1987.0      16\n",
      "1988.0      15\n",
      "1989.0      17\n",
      "1990.0      16\n",
      "1991.0      41\n",
      "1992.0      43\n",
      "1993.0      60\n",
      "1994.0     121\n",
      "1995.0     219\n",
      "1996.0     263\n",
      "1997.0     289\n",
      "1998.0     379\n",
      "1999.0     338\n",
      "2000.0     350\n",
      "2001.0     482\n",
      "2002.0     829\n",
      "2003.0     775\n",
      "2004.0     762\n",
      "2005.0     939\n",
      "2006.0    1006\n",
      "2007.0    1197\n",
      "2008.0    1427\n",
      "2009.0    1426\n",
      "2010.0    1255\n",
      "2011.0    1136\n",
      "2012.0     653\n",
      "2013.0     544\n",
      "2014.0     581\n",
      "2015.0     606\n",
      "2016.0     502\n",
      "2017.0       3\n",
      "2020.0       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "df_year_of_release = df['year_of_release'].value_counts().sort_index()\n",
    "\n",
    "print(df_year_of_release)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edbac49",
   "metadata": {},
   "source": [
    "###### _Categorization_\n",
    "\n",
    "We need to categorize the game by grouping the data into new categories we created. In this case, we're going to group the games into four categories based on the era.\n",
    "\n",
    "- Those released before 2000 will be in the 'retro' category.\n",
    "\n",
    "- Those released between 2000 and 2009 will be in the 'modern' category.\n",
    "\n",
    "- Those released after 2010 will be in the 'recent' category.\n",
    "\n",
    "- Those without a release year will be in the 'unknown' category.\n",
    "\n",
    "We want to place each game in one of these four categories and store the result in a new column.\n",
    "\n",
    "There's no pre-built Pandas function for this. Fortunately, we can write our own custom function tailored to our needs. The function should accept the release year as input and return the era category for that year as a result.\n",
    "\n",
    "This is what our custom era_group() function will look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31a0f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def era_group(year):\n",
    "    \"\"\"\n",
    "    The function returns the era group of games according to the release year using these rules:\n",
    "    —'retro' for year < 2000\n",
    "    —'modern' for 2000 <= year < 2010\n",
    "    —'recent' for year >= 2010\n",
    "    —'unknown' to search for year values ​​(NaN)\n",
    "    \"\"\"\n",
    "\n",
    "    if year < 2000:\n",
    "        return 'retro'\n",
    "    elif year < 2010:\n",
    "        return 'modern'\n",
    "    elif year >= 2010:\n",
    "        return 'recent'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c7e58",
   "metadata": {},
   "source": [
    "##### _.apply()_\n",
    "\n",
    "The apply() method allows you to apply a function along one of the axis of the DataFrame, default 0, which is the index (row) axis.\n",
    "\n",
    "_dataframe.apply(func, axis, raw, result_type, args, kwds)_\n",
    "\n",
    "_func_\t \tRequired. A function to apply to the DataFrame.\n",
    "\n",
    "_axis_\t0 1 'index' 'columns'\tOptional, Which axis to apply the function to. default 0.\n",
    "\n",
    "_raw_\tTrue False\tOptional, default False. Set to true if the row/column should be passed as an ndarray object\n",
    "\n",
    "_result_type_\t'expand' 'reduce' 'broadcast' None\tOptional, default None. Specifies how the result will be returned\n",
    "\n",
    "_args_\ta tuple\tOptional, arguments to send into the function\n",
    "\n",
    "_kwds_\tkeyword arguments\tOptional, keyword arguments to send into the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f114e9",
   "metadata": {},
   "source": [
    "In this case, the apply() method must be applied to the 'year_of_release' column, because 'year_of_release' contains the data the function will use as input. The era_group() function then becomes the argument we pass to the apply() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09c4f614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name platform  year_of_release         genre publisher  \\\n",
      "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
      "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
      "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
      "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
      "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
      "\n",
      "  developer  na_sales  eu_sales  jp_sales  critic_score user_score era_group  \n",
      "0  Nintendo     41.36     28.96      3.77          76.0          8    modern  \n",
      "1       NaN     29.08      3.58      6.81           NaN        NaN     retro  \n",
      "2  Nintendo     15.68     12.76      3.79          82.0        8.3    modern  \n",
      "3  Nintendo     15.61     10.93      3.28          80.0          8    modern  \n",
      "4       NaN     11.27      8.89     10.22           NaN        NaN     retro  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "\n",
    "df['era_group'] = df['year_of_release'].apply(era_group)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b7d2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era_group\n",
      "modern     9193\n",
      "recent     5281\n",
      "retro      1974\n",
      "unknown     269\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['era_group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7da4f1",
   "metadata": {},
   "source": [
    "##### _Excercise 01_\n",
    "\n",
    "Start by writing a function called score_group() that categorizes games based on review scores. It categorizes scores based on these characteristics:\n",
    "\n",
    "- 'low' for scores below 60.\n",
    "\n",
    "- 'medium' for scores between 60 and 79.\n",
    "\n",
    "- 'high' for scores above 80.\n",
    "\n",
    "- 'no score' for scores with no values.\n",
    "\n",
    "The score_group() function must take a numeric input called score. The output must be a string designating the score category.\n",
    "\n",
    "Make sure your function produces the correct output when passed the values ​​10, 65, 99, and np.nan. We write a separate print() statement to call each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc2c7c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low\n",
      "medium\n",
      "high\n",
      "no score\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "\n",
    "def score_group(scr):\n",
    "    \n",
    "    if scr < 60:\n",
    "        return 'low'\n",
    "    elif 59 < scr < 80:\n",
    "        return 'medium'\n",
    "    elif scr > 79:\n",
    "        return 'high'\n",
    "    else:\n",
    "        return 'no score'\n",
    "        \n",
    "\n",
    "print(score_group(10))\n",
    "print(score_group(65))\n",
    "print(score_group(99))\n",
    "print(score_group(np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a1f76",
   "metadata": {},
   "source": [
    "Add a 'score_categorized' column to the df table by applying the score_group() function to the 'critic_score' column using the apply() method. Print the first 5 rows to ensure the new column was created correctly.\n",
    "\n",
    "The precode retains the score_group() function from the previous exercise (it may look slightly different from yours, but it works the same way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0db0f7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name platform  year_of_release         genre publisher  \\\n",
      "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
      "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
      "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
      "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
      "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
      "\n",
      "  developer  na_sales  eu_sales  jp_sales  critic_score user_score  \\\n",
      "0  Nintendo     41.36     28.96      3.77          76.0          8   \n",
      "1       NaN     29.08      3.58      6.81           NaN        NaN   \n",
      "2  Nintendo     15.68     12.76      3.79          82.0        8.3   \n",
      "3  Nintendo     15.61     10.93      3.28          80.0          8   \n",
      "4       NaN     11.27      8.89     10.22           NaN        NaN   \n",
      "\n",
      "  score_categorized  \n",
      "0            medium  \n",
      "1          no score  \n",
      "2              high  \n",
      "3              high  \n",
      "4          no score  \n"
     ]
    }
   ],
   "source": [
    "df['score_categorized'] = df['critic_score'].apply(score_group)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d16a40",
   "metadata": {},
   "source": [
    "Now calculate the total North American sales for each critical score category.\n",
    "\n",
    "To do this, you need to:\n",
    "\n",
    "- Group by the new 'score_categorized' column using the groupby() method.\n",
    "\n",
    "- Calculate the sum of the 'na_sales' column of the grouped DataFrame using sum().\n",
    "\n",
    "- Display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b765179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_categorized\n",
      "high        1488.37\n",
      "low          292.16\n",
      "medium      1091.67\n",
      "no score    1528.64\n",
      "Name: na_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df.groupby('score_categorized')\n",
    "df_sum = df_grouped['na_sales'].sum()\n",
    "print(df_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caab2c8",
   "metadata": {},
   "source": [
    "##### _Excercise 02_\n",
    "\n",
    "Write a function called avg_score_group() that has one parameter named row. The row parameter must be a Pandas Series object. The function must calculate the average rating for each game, then return a string that places each game in one of these categories:\n",
    "\n",
    "- 'low' value for averages below 60.\n",
    "- 'medium' value for averages between 60 and 79.\n",
    "- 'high' value for scores above 80.\n",
    "\n",
    "To calculate the average score, avg_score_group() must take the row values ​​with the column names 'critic_score' and 'user_score'. The formula for calculating it is avg_score = (critic_score + user_score * 10) / 2.\n",
    "\n",
    "Here are the completed tests; low, medium, and high should be printed, in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low\n",
      "medium\n",
      "high\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "def avg_score_group(rw):\n",
    "    \n",
    "    avg_score = (rw['critic_score'] + rw['user_score']*10) / 2\n",
    "    \n",
    "    if avg_score < 60:\n",
    "        return 'low'\n",
    "    elif 59 < avg_score < 80:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "# parte de prueba a continuación, por favor no la cambies\n",
    "\n",
    "col_names = ['critic_score', 'user_score']\n",
    "test_low  = pd.Series([10, 1.0], index=col_names)\n",
    "test_med  = pd.Series([65, 6.5], index=col_names)\n",
    "test_high = pd.Series([99, 9.9], index=col_names)\n",
    "\n",
    "rows = [test_low, test_med, test_high]\n",
    "\n",
    "for row in rows:\n",
    "    print(avg_score_group(row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-Github_VENV-XjlEX2HA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
