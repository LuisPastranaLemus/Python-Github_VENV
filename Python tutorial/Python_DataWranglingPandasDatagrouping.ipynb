{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729d60e5",
   "metadata": {},
   "source": [
    "### __Python Datawrangling Data Grouping__\n",
    "\n",
    "[_.groupby('column_to_group_by')['column_to_aggregate'].aggregation_function()_](#groupby)\n",
    "\n",
    "[_.agg(func)_](#agg)\n",
    "\n",
    "Data Grouping has 3 phases:\n",
    "    \n",
    "    1. Divide, divide the data into groups according to a given criterion.\n",
    "    2. Apply, apply calculation methods to each group.\n",
    "    3. Combine, results are stored in a new data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf59441",
   "metadata": {},
   "source": [
    "##### _.groupby()_ <a index='groupBy'></a>\n",
    "\n",
    "The groupby() method allows you to group your data and execute functions on these groups.\n",
    "\n",
    "_dataframe.groupby(by, axis, level, as_index, sort, group_keys, observed, dropna)_\n",
    "\n",
    "_by_ \t     Required. A label, a list of labels, or a function used to specify how to group the DataFrame.\n",
    "\n",
    "_axis_\t0 1 'index' 'columns'\tOptional, Which axis to make the group by, default 0.\n",
    "\n",
    "_level_\tlevel None\tOptional. Specify if grouping should be done by a certain level. Default None\n",
    "\n",
    "_as_index_\tTrue False\tOptional, default True. Set to False if the result should NOT use the group labels as index\n",
    "\n",
    "_sort_\tTrue False\tOptional, default True. Set to False if the result should NOT sort the group keys (for better performance)\n",
    "\n",
    "_group_keys_\tTrue False\tOptional, default True. Set to False if the result should NOT add the group keys to index\n",
    "\n",
    "_dropna_\tTrue False\tOptional, default True. Set to False if the result should include the rows/columns where the group key is a NULL value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6001d",
   "metadata": {},
   "source": [
    "_df.groupby('column_to_group_by')['column_to_aggregate'].aggregation_function()_\n",
    "\n",
    "__Common Aggregation Functions__\n",
    "\n",
    "You can use:\n",
    "\n",
    ".sum() — total\n",
    "\n",
    ".mean() — average\n",
    "\n",
    ".count() — number of rows\n",
    "\n",
    ".max() / .min() — highest/lowest\n",
    "\n",
    ".median(), .std(), .nunique(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dde447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  store     month  sales\n",
      "0     A   january    100\n",
      "1     A   january    200\n",
      "2     B   octuber     50\n",
      "3     B      june    300\n",
      "4     B  february    150\n",
      "5     C  december    400\n",
      "\n",
      "store\n",
      "A    300\n",
      "B    500\n",
      "C    400\n",
      "Name: sales, dtype: int64\n",
      "\n",
      "store  month   \n",
      "A      january     300\n",
      "B      february    150\n",
      "       june        300\n",
      "       octuber      50\n",
      "C      december    400\n",
      "Name: sales, dtype: int64\n",
      "\n",
      "       sum        mean  count\n",
      "store                        \n",
      "A      300  150.000000      2\n",
      "B      500  166.666667      3\n",
      "C      400  400.000000      1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>december</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>february</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>january</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>june</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>octuber</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  sales\n",
       "0  december  400.0\n",
       "1  february  150.0\n",
       "2   january  150.0\n",
       "3      june  300.0\n",
       "4   octuber   50.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'store': ['A', 'A', 'B', 'B', 'B', 'C'],\n",
    "    'month': ['january', 'january', 'octuber', 'june', 'february', 'december'],\n",
    "    'sales': [100, 200, 50, 300, 150, 400]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "print(df.groupby('store')['sales'].sum())\n",
    "print()\n",
    "print(df.groupby(['store', 'month'])['sales'].sum())\n",
    "print()\n",
    "print(df.groupby('store')['sales'].agg(['sum', 'mean', 'count']))\n",
    "print()\n",
    "df.groupby(\"month\", as_index=False)[\"sales\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e476771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         co2   model\n",
      "car                 \n",
      "Ford   100.5  Fiesta\n",
      "Skoda   97.0  Citigo\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "  'co2': [95, 90, 99, 104, 105, 94, 99, 104],\n",
    "  'model': ['Citigo', 'Fabia', 'Fiesta', 'Rapid', 'Focus', 'Mondeo', 'Octavia', 'B-Max'],\n",
    "  'car': ['Skoda', 'Skoda', 'Ford', 'Skoda', 'Ford', 'Ford', 'Skoda', 'Ford']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "result = df.groupby([\"car\"]).agg({\n",
    "    'co2': 'mean',  # Calculate mean for 'co2'\n",
    "    'model': 'first'  # Take the first value for 'model'\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e78222",
   "metadata": {},
   "source": [
    "##### __Example 1__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7da60",
   "metadata": {},
   "source": [
    "For Exoplantes, get the count of each discovered group according to their radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6631f5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    num        name  Property      mass    radius  discovered\n",
      "0     0   1RXS1609b         0  14.00000  19.04000        2008\n",
      "1     1  2M0122-24b         1  20.00000  11.20000        2013\n",
      "2     2  2M0219-39b         2  13.90000  16.12800        2015\n",
      "3     3  2M0746+20b         3  12.21000  10.86400        2010\n",
      "4     4  2M2140+16b         4  20.00000  10.30400        2010\n",
      "5     5  2M2206-20b         5  30.00000  14.56000        2010\n",
      "6     6      51Erib         6   9.10000  12.43200        2015\n",
      "7     7      51Pegb         7   0.47000  21.28000        1995\n",
      "8     8      55Cnce         8   0.02703   1.94544        2004\n",
      "9     9   BD+20594b         9   0.05130   2.22880        2016\n",
      "10   10  BD-103166b        10   0.46000  11.53600        2000\n",
      "11   11      CTChab        11  17.00000  24.64000        2008\n",
      "12   12     CVSO30b        12   6.20000  21.39200        2012\n",
      "13   13    CoRoT-1b        13   1.03000  16.68800        2007\n",
      "14   14   CoRoT-10b        14   2.75000  10.86400        2010\n",
      "15   15   CoRoT-11b        15   2.33000  16.01600        2010\n",
      "16   16   CoRoT-12b        16   0.91700  16.12800        2010\n",
      "17   17   CoRoT-13b        17   1.30800   9.91200        2010\n",
      "18   18   CoRoT-14b        18   7.60000  12.20800        2010\n",
      "19   19   CoRoT-15b        19  63.40000  12.54400        2010\n",
      "20   20   CoRoT-16b        20   0.53500  13.10400        2010\n",
      "21   21   CoRoT-17b        21   2.43000  11.42400        2010\n",
      "22   22   CoRoT-18b        22   3.47000  14.67200        2011\n",
      "23   23   CoRoT-19b        23   1.11000  14.44800        2011\n",
      "24   24    CoRoT-2b        24   3.31000  16.40800        2007\n",
      "25   25   CoRoT-20b        25   4.24000   9.40800        2011\n",
      "26   26   CoRoT-21b        26   2.26000  14.56000        2011\n",
      "27   27   CoRoT-22b        27   0.06000   4.87648        2011\n",
      "28   28   CoRoT-23b        28   2.80000  12.09600        2011\n",
      "29   29   CoRoT-24b        29   0.01800   3.69600        2011\n",
      "\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002051541FAD0>\n",
      "\n",
      "discovered\n",
      "1995     1\n",
      "2000     1\n",
      "2004     1\n",
      "2007     2\n",
      "2008     2\n",
      "2010    11\n",
      "2011     7\n",
      "2012     1\n",
      "2013     1\n",
      "2015     2\n",
      "2016     1\n",
      "Name: radius, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_exoplanets = pd.read_csv('DataSets/exoplanet.csv')\n",
    "\n",
    "print(df_exoplanets)\n",
    "print()\n",
    "\n",
    "print(df_exoplanets.groupby(by='discovered')) # print(exoplanet.groupby('discovered'))\n",
    "print() \n",
    "\n",
    "df_exo_number = df_exoplanets.groupby(by='discovered')[\"radius\"].count() # df_exonumber = exoplanet.groupby('discovered').count())\n",
    "print(df_exo_number) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ebdaf",
   "metadata": {},
   "source": [
    "For Exoplantes, get the sum of each discovered group according to their radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55016d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discovered\n",
      "1995     21.28000\n",
      "2000     11.53600\n",
      "2004      1.94544\n",
      "2007     33.09600\n",
      "2008     43.68000\n",
      "2010    137.92800\n",
      "2011     73.75648\n",
      "2012     21.39200\n",
      "2013     11.20000\n",
      "2015     28.56000\n",
      "2016      2.22880\n",
      "Name: radius, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_exo_radius_sum = df_exoplanets.groupby('discovered')['radius'].sum()\n",
    "print(df_exo_radius_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46590473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discovered\n",
      "1995    21.280000\n",
      "2000    11.536000\n",
      "2004     1.945440\n",
      "2007    16.548000\n",
      "2008    21.840000\n",
      "2010    12.538909\n",
      "2011    10.536640\n",
      "2012    21.392000\n",
      "2013    11.200000\n",
      "2015    14.280000\n",
      "2016     2.228800\n",
      "Name: radius, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_exo_radius_mean = df_exo_radius_sum / df_exo_number \n",
    "print(df_exo_radius_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d623323",
   "metadata": {},
   "source": [
    "##### __Example 2__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf344ff2",
   "metadata": {},
   "source": [
    "You must group Digimon by their evolution level (Stage), and then apply different aggregation methods to this grouping to obtain the following information:\n",
    "\n",
    "- The total number of Digimon by level (Stage).\n",
    "\n",
    "- The sum of the health values ​​(LV 50 HP) by level.\n",
    "\n",
    "- The average speed values ​​(LV 50 Spd) by level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d35aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de los Digimons \n",
      " Stage\n",
      "Armor           3\n",
      "Baby            5\n",
      "Champion       54\n",
      "In-Training    11\n",
      "Mega           74\n",
      "Rookie         38\n",
      "Ultimate       58\n",
      "Ultra           6\n",
      "Name: Digimon, dtype: int64 \n",
      "\n",
      "Total de Salud \n",
      " Stage\n",
      "Armor            3510\n",
      "Baby             3640\n",
      "Champion        58700\n",
      "In-Training      9290\n",
      "Mega           107700\n",
      "Rookie          34980\n",
      "Ultimate        74640\n",
      "Ultra            9050\n",
      "Name: Lv 50 HP, dtype: int64 \n",
      "\n",
      "Promedio Nivel de Velocidad \n",
      " Stage\n",
      "Armor          128.666667\n",
      "Baby            77.000000\n",
      "Champion       103.259259\n",
      "In-Training     81.181818\n",
      "Mega           152.486486\n",
      "Rookie          90.236842\n",
      "Ultimate       122.586207\n",
      "Ultra          152.833333\n",
      "Name: Lv50 Spd, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "digimon_data = pd.read_csv('DataSets/DigiDB_digimonlist.csv')\n",
    "\n",
    "\n",
    "grouped_stage_count =  digimon_data.groupby(\"Stage\")[\"Digimon\"].count()\n",
    "grouped_stage_sum =  digimon_data.groupby(\"Stage\")[\"Lv 50 HP\"].sum()\n",
    "grouped_stage_mean =  digimon_data.groupby(\"Stage\")[\"Lv50 Spd\"].mean()\n",
    "\n",
    "\n",
    "print('Distribución de los Digimons', '\\n',grouped_stage_count,'\\n')\n",
    "print('Total de Salud', '\\n',grouped_stage_sum, '\\n',)\n",
    "print('Promedio Nivel de Velocidad', '\\n',grouped_stage_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77f79a",
   "metadata": {},
   "source": [
    "##### _Processing grouped data with agg()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615c74b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                name platform  year_of_release         genre  \\\n",
      "0                         Wii Sports      Wii           2006.0        Sports   \n",
      "1                  Super Mario Bros.      NES           1985.0      Platform   \n",
      "2                     Mario Kart Wii      Wii           2008.0        Racing   \n",
      "3                  Wii Sports Resort      Wii           2009.0        Sports   \n",
      "4           Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing   \n",
      "...                              ...      ...              ...           ...   \n",
      "16712  Samurai Warriors: Sanada Maru      PS3           2016.0        Action   \n",
      "16713               LMA Manager 2007     X360           2006.0        Sports   \n",
      "16714        Haitaka no Psychedelica      PSV           2016.0     Adventure   \n",
      "16715               Spirits & Spells      GBA           2003.0      Platform   \n",
      "16716            Winning Post 8 2016      PSV           2016.0    Simulation   \n",
      "\n",
      "          publisher developer  na_sales  eu_sales  jp_sales  critic_score  \\\n",
      "0          Nintendo  Nintendo     41.36     28.96      3.77          76.0   \n",
      "1          Nintendo       NaN     29.08      3.58      6.81           NaN   \n",
      "2          Nintendo  Nintendo     15.68     12.76      3.79          82.0   \n",
      "3          Nintendo  Nintendo     15.61     10.93      3.28          80.0   \n",
      "4          Nintendo       NaN     11.27      8.89     10.22           NaN   \n",
      "...             ...       ...       ...       ...       ...           ...   \n",
      "16712    Tecmo Koei       NaN      0.00      0.00      0.01           NaN   \n",
      "16713   Codemasters       NaN      0.00      0.01      0.00           NaN   \n",
      "16714  Idea Factory       NaN      0.00      0.00      0.01           NaN   \n",
      "16715       Wanadoo       NaN      0.01      0.00      0.00           NaN   \n",
      "16716    Tecmo Koei       NaN      0.00      0.00      0.01           NaN   \n",
      "\n",
      "      user_score  \n",
      "0              8  \n",
      "1            NaN  \n",
      "2            8.3  \n",
      "3              8  \n",
      "4            NaN  \n",
      "...          ...  \n",
      "16712        NaN  \n",
      "16713        NaN  \n",
      "16714        NaN  \n",
      "16715        NaN  \n",
      "16716        NaN  \n",
      "\n",
      "[16717 rows x 11 columns]\n",
      "\n",
      "                          name platform  year_of_release      genre  \\\n",
      "0                   Wii Sports      Wii           2006.0     Sports   \n",
      "2               Mario Kart Wii      Wii           2008.0     Racing   \n",
      "3            Wii Sports Resort      Wii           2009.0     Sports   \n",
      "6        New Super Mario Bros.       DS           2006.0   Platform   \n",
      "7                     Wii Play      Wii           2006.0       Misc   \n",
      "...                        ...      ...              ...        ...   \n",
      "16698                   Breach       PC           2011.0    Shooter   \n",
      "16699         Bust-A-Move 3000       GC           2003.0     Puzzle   \n",
      "16700         Mega Brain Boost       DS           2008.0     Puzzle   \n",
      "16704  STORM: Frontline Nation       PC           2011.0   Strategy   \n",
      "16707                  15 Days       PC           2009.0  Adventure   \n",
      "\n",
      "                   publisher           developer  na_sales  eu_sales  \\\n",
      "0                   Nintendo            Nintendo     41.36     28.96   \n",
      "2                   Nintendo            Nintendo     15.68     12.76   \n",
      "3                   Nintendo            Nintendo     15.61     10.93   \n",
      "6                   Nintendo            Nintendo     11.28      9.14   \n",
      "7                   Nintendo            Nintendo     13.96      9.18   \n",
      "...                      ...                 ...       ...       ...   \n",
      "16698              Destineer        Atomic Games      0.01      0.00   \n",
      "16699                Ubisoft   Taito Corporation      0.01      0.00   \n",
      "16700  Majesco Entertainment  Interchannel-Holon      0.01      0.00   \n",
      "16704                Unknown              SimBin      0.00      0.01   \n",
      "16707      DTP Entertainment   DTP Entertainment      0.00      0.01   \n",
      "\n",
      "       jp_sales  critic_score user_score  \n",
      "0          3.77          76.0          8  \n",
      "2          3.79          82.0        8.3  \n",
      "3          3.28          80.0          8  \n",
      "6          6.50          89.0        8.5  \n",
      "7          2.93          58.0        6.6  \n",
      "...         ...           ...        ...  \n",
      "16698      0.00          61.0        5.8  \n",
      "16699      0.00          53.0        tbd  \n",
      "16700      0.00          48.0        tbd  \n",
      "16704      0.00          60.0        7.2  \n",
      "16707      0.00          63.0        5.8  \n",
      "\n",
      "[7943 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "print(df)\n",
    "print()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cad9a5",
   "metadata": {},
   "source": [
    "Let's say we need the average critic score for each genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43ecfad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Action          66.701897\n",
      "Adventure       65.229299\n",
      "Fighting        69.158416\n",
      "Misc            66.608696\n",
      "Platform        68.173824\n",
      "Puzzle          67.152778\n",
      "Racing          68.068245\n",
      "Role-Playing    72.655267\n",
      "Shooter         70.260022\n",
      "Simulation      68.567723\n",
      "Sports          71.972318\n",
      "Strategy        72.282313\n",
      "Name: critic_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_score = df.groupby('genre')['critic_score'].mean()\n",
    "print(mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf5555",
   "metadata": {},
   "source": [
    "The index of the Series mean_score object is the “groupby() key,” in this case, the unique values ​​in the 'genre' column. Performing a groupby() operation changes the row index of the data to the keys we're grouping by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd12d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform  genre       \n",
      "3DS       Action          62.982759\n",
      "          Adventure       67.500000\n",
      "          Fighting        68.857143\n",
      "          Misc            69.100000\n",
      "          Platform        72.444444\n",
      "                            ...    \n",
      "XOne      Role-Playing    80.777778\n",
      "          Shooter         77.656250\n",
      "          Simulation      59.000000\n",
      "          Sports          71.093750\n",
      "          Strategy        70.000000\n",
      "Name: critic_score, Length: 197, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grp = df.groupby(['platform', 'genre'])\n",
    "print(grp['critic_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e5d6c",
   "metadata": {},
   "source": [
    "Now we have the average critic score for each genre on each platform. Since we grouped by two columns, our result is a multi-index Series object with two index values ​​for each average score, in this case, 'platform' and 'genre'.\n",
    "\n",
    "Here, the grp variable is an object that contains the grouped DataFrame before we process each group with the mean() method. It's called a \"standby\" object. If we try to print the grp object, it will display a text representation of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb38fc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000026BD9B98910>\n"
     ]
    }
   ],
   "source": [
    "grp = df.groupby(['platform', 'genre'])\n",
    "print(grp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bf608",
   "metadata": {},
   "source": [
    "When we print df.groupby('column_name'), we don't see a table printed as we would if we printed df. Instead, we see the data type of the grouped object (DataFrameGroupBy) and a string (0x0000022EA82A75B0) representing the location in the computer's memory where the object is stored. No output is displayed until we process the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8e7bd",
   "metadata": {},
   "source": [
    "##### __Split-Apply-Merge__\n",
    "\n",
    "The DataFrameGroubBy object is part of a data processing framework called split-apply-merge:\n",
    "\n",
    "1 split the data into groups;\n",
    "\n",
    "2 apply a statistical aggregation function to each group;\n",
    "\n",
    "3 combine the results for each group.\n",
    "\n",
    "In the code below, we can illustrate each of the three components of split-apply-merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "787f3731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform  genre       \n",
      "3DS       Action          62.982759\n",
      "          Adventure       67.500000\n",
      "          Fighting        68.857143\n",
      "          Misc            69.100000\n",
      "          Platform        72.444444\n",
      "                            ...    \n",
      "XOne      Role-Playing    80.777778\n",
      "          Shooter         77.656250\n",
      "          Simulation      59.000000\n",
      "          Sports          71.093750\n",
      "          Strategy        70.000000\n",
      "Name: critic_score, Length: 197, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grp = df.groupby(['platform', 'genre'])\n",
    "mean_scores = grp['critic_score'].mean()\n",
    "print(mean_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959621a",
   "metadata": {},
   "source": [
    "We split the data into groups using df.groupby(['platform', 'genre']), apply the mean() method, and combine the results into a Series object, grp['critic_score'].mean().\n",
    "\n",
    "Of course, we can skip creating the grp and mean_scores objects and have pandas perform all three steps in a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b207e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform  genre       \n",
      "3DS       Action          62.982759\n",
      "          Adventure       67.500000\n",
      "          Fighting        68.857143\n",
      "          Misc            69.100000\n",
      "          Platform        72.444444\n",
      "                            ...    \n",
      "XOne      Role-Playing    80.777778\n",
      "          Shooter         77.656250\n",
      "          Simulation      59.000000\n",
      "          Sports          71.093750\n",
      "          Strategy        70.000000\n",
      "Name: critic_score, Length: 197, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['platform', 'genre'])['critic_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94462ecb",
   "metadata": {},
   "source": [
    "##### _.agg()_ <a index='agg'></a>\n",
    "\n",
    "The agg() method allows you to apply a function or a list of function names to be executed along one of the axis of the DataFrame, default 0, which is the index (row) axis.\n",
    "\n",
    "_dataframe.agg(func, axis, args, kwargs)_\n",
    "\n",
    "_func_\t \tRequired. A function, function name, or a list of function names to apply to the DataFrame.\n",
    "\n",
    "_axis_\t0 1 'index' 'columns'\tOptional, Which axis to apply the function to. default 0.\n",
    "\n",
    "_args_\t \tOptional, arguments to send into the function\n",
    "\n",
    "_kwargs_\t \tOptional, keyword arguments to send into the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e1e96",
   "metadata": {},
   "source": [
    "So far, we've only applied a single function to our groups. But what if we want to calculate different summary statistics for different columns? For example, both the average review score and total sales in Japan for each group? We can do this using the agg() method, which is short for \"aggregate.\"\n",
    "\n",
    "The agg() method uses a dictionary as input where the keys are the column names and the corresponding values ​​are the aggregation functions you want to apply to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff93808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       critic_score  jp_sales\n",
      "platform genre                               \n",
      "3DS      Action           62.982759      6.60\n",
      "         Adventure        67.500000      0.66\n",
      "         Fighting         68.857143      0.46\n",
      "         Misc             69.100000      1.22\n",
      "         Platform         72.444444      5.94\n",
      "...                             ...       ...\n",
      "XOne     Role-Playing     80.777778      0.01\n",
      "         Shooter          77.656250      0.13\n",
      "         Simulation       59.000000      0.00\n",
      "         Sports           71.093750      0.02\n",
      "         Strategy         70.000000      0.00\n",
      "\n",
      "[197 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "agg_dict = {'critic_score': 'mean', 'jp_sales': 'sum'}\n",
    "\n",
    "grp = df.groupby(['platform', 'genre'])\n",
    "print(grp.agg(agg_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184c4857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       jp_sales\n",
      "platform genre                 \n",
      "3DS      Action           13.20\n",
      "         Adventure         1.32\n",
      "         Fighting          0.92\n",
      "         Misc              2.44\n",
      "         Platform         11.88\n",
      "...                         ...\n",
      "XOne     Role-Playing      0.02\n",
      "         Shooter           0.26\n",
      "         Simulation        0.00\n",
      "         Sports            0.04\n",
      "         Strategy          0.00\n",
      "\n",
      "[197 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "def double_it(sales):\n",
    "    sales = sales.sum() * 2 # multiplica la suma anterior por 2\n",
    "    return sales\n",
    "\n",
    "agg_dict = {'jp_sales': double_it}\n",
    "\n",
    "grp = df.groupby(['platform', 'genre'])\n",
    "print(grp.agg(agg_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd39e0",
   "metadata": {},
   "source": [
    "##### __Excercis 01__\n",
    "\n",
    "Create a 'total_sales' column. You'll use these columns, so make a note of their names.\n",
    "\n",
    "The precode then groups the DataFrame df by the 'genre' column and assigns the resulting grouped object to the grp variable.\n",
    "\n",
    "Now you'll do the following:\n",
    "\n",
    "- Create a dictionary to calculate for each genre:\n",
    "- Sum of total sales.\n",
    "- Average sales NA (North America).\n",
    "- Average sales EU (Europe).\n",
    "- Average sales JP (Japan).\n",
    "- Assign the dictionary to a variable called agg_dict with the tuples described above.\n",
    "- Assign the result of agg() to a variable called genre.\n",
    "- Print genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "865e1a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total_sales  na_sales  eu_sales  jp_sales\n",
      "genre                                                  \n",
      "Action            1559.58  0.260834  0.154045  0.047905\n",
      "Adventure          221.10  0.080783  0.048764  0.040138\n",
      "Fighting           411.17  0.263086  0.118174  0.103039\n",
      "Misc               728.12  0.232726  0.121566  0.061777\n",
      "Platform           776.68  0.501689  0.225619  0.147331\n",
      "Puzzle             230.19  0.211845  0.086224  0.098810\n",
      "Racing             652.57  0.287710  0.189359  0.045404\n",
      "Role-Playing       874.98  0.220540  0.125807  0.236973\n",
      "Shooter            948.34  0.447649  0.239864  0.029297\n",
      "Simulation         359.51  0.208455  0.129886  0.072998\n",
      "Sports            1196.76  0.291495  0.160473  0.057726\n",
      "Strategy           163.38  0.100366  0.066135  0.072709\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataSets/vg_sales.csv')\n",
    "df['total_sales'] = df['na_sales'] + df['eu_sales'] + df['jp_sales']\n",
    "\n",
    "grp = df.groupby('genre')\n",
    "\n",
    "agg_dict = {'total_sales':'sum', 'na_sales':'mean', 'eu_sales':'mean', 'jp_sales':'mean'}\n",
    "\n",
    "genre = grp.agg(agg_dict)\n",
    "\n",
    "print(genre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-Github_VENV-XjlEX2HA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
