{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5b8e70",
   "metadata": {},
   "source": [
    "### __Python Data Wrangling Duplicate and Abscent values__\n",
    "\n",
    "[_.value_countsdropna=False](#valueCounts)\n",
    "\n",
    "[_df_logs = pd.read_csv('path', keep_default_na=False)](#keepDefaultNA)\n",
    "\n",
    "[_df.groupby('column_to_group_by')['column_to_aggregate'].aggregation_function()_](#groupBy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27877d35",
   "metadata": {},
   "source": [
    "##### __Count missing values__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e5d71",
   "metadata": {},
   "source": [
    "There are many ways to find and count missing values ​​in pandas. In this lesson, you learned three ways:\n",
    "\n",
    "Calling info() on a DataFrame.\n",
    "\n",
    "Calling isna().sum() on a DataFrame or Series.\n",
    "\n",
    "Calling value_counts(dropna=False) on a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5071a4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   user_id   200000 non-null  int64 \n",
      " 1   source    198326 non-null  object\n",
      " 2   email     13953 non-null   object\n",
      " 3   purchase  200000 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('DataSets/visit_log.csv')\n",
    "\n",
    "df_logs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de729619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id          0\n",
      "source        1674\n",
      "email       186047\n",
      "purchase         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_logs.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770248a7",
   "metadata": {},
   "source": [
    "Let's look at another way to find missing values. Let's use value_counts() on the 'source' column, but add the dropna=False parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec68ec",
   "metadata": {},
   "source": [
    "##### _.values_counts()_ <a index='valueCounts'></a>\n",
    "\n",
    "Return a Series containing the frequency of each distinct row in the Dataframe.\n",
    "\n",
    "_DataFrame.value_counts(subset=None, normalize=False, sort=True, ascending=False, dropna=True)_\n",
    "\n",
    "_subset_ label or list of labels, optional, Columns to use when counting unique combinations.\n",
    "\n",
    "_normalize_ bool, default False, Return proportions rather than frequencies.\n",
    "\n",
    "_sort_ bool, default True, Sort by frequencies when True. Sort by DataFrame column values when False.\n",
    "\n",
    "_ascending_ bool, default False, Sort in ascending order.\n",
    "\n",
    "_dropna_ bool, default True, Don’t include counts of rows that contain NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "294d8cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "other      133834\n",
      "context     52032\n",
      "email       12279\n",
      "NaN          1674\n",
      "undef         181\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_logs['source'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f292566",
   "metadata": {},
   "source": [
    "##### __Filter missing values__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fec8d9",
   "metadata": {},
   "source": [
    "Filter the DataFrame and extract only the rows that do not have a missing 'source'. The approach we used above will work with one minor modification:\n",
    "\n",
    "The only difference between this case and the one we were interested in for rows with missing values ​​is the addition of the tilde __symbol (~)__, which inverts the result. Here's the breakdown of this code:\n",
    "\n",
    "- We extract the 'source' column using df_logs['source'].\n",
    "\n",
    "- Next, we apply the isna() method to it to obtain a series of Booleans indicating missing values: df_logs['source'].isna().\n",
    "\n",
    "- We invert the series using ~. This inverts all True values ​​to False and vice versa.\n",
    "\n",
    "- We use this series of Booleans to filter the original DataFrame, extracting only the rows in which 'source' has no missing values.\n",
    "\n",
    "- Finally, we print the resulting table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c88449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           user_id   source       email  purchase\n",
      "0       7141786820    other         NaN         0\n",
      "1       5644686960    email  c129aa540a         0\n",
      "2       1914055396  context         NaN         0\n",
      "3       4099355752    other         NaN         0\n",
      "4       6032477554  context         NaN         1\n",
      "...            ...      ...         ...       ...\n",
      "199995  8714621942    other         NaN         0\n",
      "199996  6064948744  context         NaN         1\n",
      "199997  9210683879  context         NaN         0\n",
      "199998  1629959686    other         NaN         1\n",
      "199999  2089329795    other         NaN         0\n",
      "\n",
      "[198326 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_logs[~df_logs['source'].isna()]) # Display non-null source values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6902b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           user_id source       email  purchase\n",
      "22      1397217221    NaN  79ac569f0b         0\n",
      "49      5062457902    NaN  9ddce3a861         0\n",
      "171     6724868284    NaN  c0e48c7cf8         0\n",
      "258     3221384063    NaN  7fe8da1823         0\n",
      "379     7515782311    NaN  462462af10         0\n",
      "...            ...    ...         ...       ...\n",
      "199342  3439213943    NaN  7edda4e2a4         0\n",
      "199661  9473123762    NaN  3535509f51         0\n",
      "199689   722485056    NaN  470ffa3800         0\n",
      "199709  5950023506    NaN  0fb749d485         0\n",
      "199758  3747926428    NaN  604850216f         0\n",
      "\n",
      "[1674 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_logs[df_logs['source'].isna()]) # Display null source values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b17e58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           user_id source       email  purchase\n",
      "1       5644686960  email  c129aa540a         0\n",
      "11      8623045648  email  d6d19c571c         0\n",
      "18      5739438900  email  19379ee49c         0\n",
      "19      7486955288  email  09c27794fa         0\n",
      "33      7298923004  email  1fe184ed73         0\n",
      "...            ...    ...         ...       ...\n",
      "199922  4075894991  email  2c9a202435         0\n",
      "199958  9794381984  email  85712b433a         0\n",
      "199970  3396355438  email  4bba3fde78         0\n",
      "199979  5008169696  email  e5128e15fd         0\n",
      "199989  9470921783  email  3977de6aaa         0\n",
      "\n",
      "[12279 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_logs[(~df_logs['email'].isna()) & (df_logs['source'] == 'email')]) # Display rows where email is not null and source is 'email'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445c9095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id source       email  purchase\n",
      "1   5644686960  email  c129aa540a         0\n",
      "11  8623045648  email  d6d19c571c         0\n",
      "18  5739438900  email  19379ee49c         0\n",
      "19  7486955288  email  09c27794fa         0\n",
      "22  1397217221    NaN  79ac569f0b         0\n",
      "33  7298923004  email  1fe184ed73         0\n",
      "43  6034222291  email  fb58a27f03         0\n",
      "49  5062457902    NaN  9ddce3a861         0\n",
      "56  5690036640  email  a088a48182         0\n",
      "66  9963049355  email  9cc43ebd15         0\n"
     ]
    }
   ],
   "source": [
    "df_emails = df_logs[~df_logs['email'].isna()] # Filter rows where email is not null\n",
    "\n",
    "print(df_emails.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails = df_logs[(df_logs[\"email\"].isna()) & (df_logs[\"source\"].isna())] # Filter rows where email and source are both null\n",
    "\n",
    "print(df_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1841ff",
   "metadata": {},
   "source": [
    "##### __Fill in missing categorical values__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb8b3f",
   "metadata": {},
   "source": [
    "##### _Quantitative vs. Categorical Variables_\n",
    "\n",
    "Quantitative variables have numerical values ​​that we can use for arithmetic calculations, for example, height, weight, age, and income. In Python, these values ​​tend to be stored as integers or floats.\n",
    "\n",
    "Categorical variables represent a set of possible values ​​that a particular observation can have, for example, the color, make, and model of a car. In Python, these values ​​tend to be stored as strings, but they can also be Boolean values ​​or even integers.\n",
    "\n",
    "Some examples of integer categorical values ​​are postal codes or numerical labels that represent other values ​​(e.g., 1 = red, 2 = blue, etc.). In either case, it doesn't make sense to perform arithmetic operations on categorical values.\n",
    "\n",
    "The way we fill in missing values ​​depends on whether they are quantitative or categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e79864",
   "metadata": {},
   "source": [
    "__keep_default_na=False__ makes NaN values become _empty strings_. Work as .fillna() <a index='keppDefaultNA'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa7836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id   source       email  purchase\n",
      "0  7141786820    other                     0\n",
      "1  5644686960    email  c129aa540a         0\n",
      "2  1914055396  context                     0\n",
      "3  4099355752    other                     0\n",
      "4  6032477554  context                     1\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   user_id   200000 non-null  int64 \n",
      " 1   source    200000 non-null  object\n",
      " 2   email     200000 non-null  object\n",
      " 3   purchase  200000 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('DataSets/visit_log.csv', keep_default_na=False) # Read CSV file without default NA values, work as .fillna()\n",
    "\n",
    "print(df_logs.head())\n",
    "print()\n",
    "df_logs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb7742",
   "metadata": {},
   "source": [
    "##### __Excercise__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df35dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id   source       email  purchase\n",
      "0  7141786820    other                     0\n",
      "1  5644686960    email  c129aa540a         0\n",
      "2  1914055396  context                     0\n",
      "3  4099355752    other                     0\n",
      "4  6032477554  context                     1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_logs = pd.read_csv('DataSets/visit_log.csv')\n",
    "\n",
    "df_logs['email'] = df_logs['email'].fillna(value='')\n",
    "print(df_logs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad8ea5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other' 'email' 'context' '' 'undef']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('DataSets/visit_log.csv', keep_default_na=False)\n",
    "\n",
    "df_sources = df_logs['source'].unique()\n",
    "print(df_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c2801e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other' 'email' 'context' 'undef']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('DataSets/visit_log.csv', keep_default_na=False)\n",
    "\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "print(df_logs['source'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcec15fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "context     52032\n",
      "email       13953\n",
      "other      133834\n",
      "undef         181\n",
      "Name: user_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('DataSets/visit_log.csv', keep_default_na=False)\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "\n",
    "visits = df_logs.groupby('source')['user_id'].count()\n",
    "print(visits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e207d8af",
   "metadata": {},
   "source": [
    "##### _.groupby()_ <a index='groupBy'></a>\n",
    "\n",
    "The .groupby() method in Pandas splits your DataFrame into groups based on a particular column (or columns), then allows you to apply some operation to each group — such as calculating a sum, mean, count, or even custom functions.\n",
    "\n",
    "_df.groupby('column_to_group_by')['column_to_aggregate'].aggregation_function()_\n",
    "\n",
    "__Common Aggregation Functions__\n",
    "\n",
    "You can use:\n",
    "\n",
    ".sum() — total\n",
    "\n",
    ".mean() — average\n",
    "\n",
    ".count() — number of rows\n",
    "\n",
    ".max() / .min() — highest/lowest\n",
    "\n",
    ".median(), .std(), .nunique(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ad817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  store     month  sales\n",
      "0     A   january    100\n",
      "1     A   january    200\n",
      "2     B   octuber     50\n",
      "3     B      june    300\n",
      "4     B  february    150\n",
      "5     C  december    400\n",
      "\n",
      "store\n",
      "A    300\n",
      "B    500\n",
      "C    400\n",
      "Name: sales, dtype: int64\n",
      "\n",
      "store  month   \n",
      "A      january     300\n",
      "B      february    150\n",
      "       june        300\n",
      "       octuber      50\n",
      "C      december    400\n",
      "Name: sales, dtype: int64\n",
      "\n",
      "       sum        mean  count\n",
      "store                        \n",
      "A      300  150.000000      2\n",
      "B      500  166.666667      3\n",
      "C      400  400.000000      1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>december</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>february</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>january</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>june</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>octuber</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  sales\n",
       "0  december  400.0\n",
       "1  february  150.0\n",
       "2   january  150.0\n",
       "3      june  300.0\n",
       "4   octuber   50.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'store': ['A', 'A', 'B', 'B', 'B', 'C'],\n",
    "    'month': ['january', 'january', 'octuber', 'june', 'february', 'december'],\n",
    "    'sales': [100, 200, 50, 300, 150, 400]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "print(df.groupby('store')['sales'].sum())\n",
    "print()\n",
    "print(df.groupby(['store', 'month'])['sales'].sum())\n",
    "print()\n",
    "print(df.groupby('store')['sales'].agg(['sum', 'mean', 'count']))\n",
    "print()\n",
    "df.groupby(\"month\", as_index=False)[\"sales\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24d4c74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "context    3029\n",
      "email      1021\n",
      "other      8041\n",
      "undef        12\n",
      "Name: purchase, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('DataSets/visit_log.csv', keep_default_na=False)\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "\n",
    "purchases = df_logs.groupby('source')['purchase'].sum()\n",
    "print(purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a1ac4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "context    0.058214\n",
      "email      0.073174\n",
      "other      0.060082\n",
      "undef      0.066298\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('DataSets/visit_log.csv', keep_default_na=False)\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "\n",
    "visits = df_logs.groupby('source')['user_id'].count()\n",
    "purchases = df_logs.groupby('source')['purchase'].sum()\n",
    "\n",
    "conversion = purchases / visits\n",
    "print(conversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d0b792",
   "metadata": {},
   "source": [
    "##### __Fill in missing quantitative values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bddbcae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id device_type   age    time\n",
      "0  7141786820     desktop  33.0  2127.0\n",
      "1  5644686960      mobile  30.0    35.0\n",
      "2  1914055396     desktop  25.0     NaN\n",
      "3  4099355752     desktop  25.0  2123.0\n",
      "4  6032477554     desktop  27.0    59.0\n",
      "5  5872473344      mobile  27.0     NaN\n",
      "6  7977025176      mobile   NaN     NaN\n",
      "7  3512872755     desktop  40.0    65.0\n",
      "8  1827368713     desktop  37.0     NaN\n",
      "9  8688870165     desktop  36.0  2124.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('DataSets/web_analytics_data.csv')\n",
    "print(analytics_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893e44d",
   "metadata": {},
   "source": [
    "mean() used when there are no atypical significant values\n",
    "\n",
    "median() used when there are atypical significant values\n",
    "\n",
    "The mean is not a good typical value when the data you are working with has significant outliers. For example, suppose five employees at a company have salaries of $30,000. Both the mean and median are equal to $30,000.\n",
    "\n",
    "Then, a marketing director is hired with a salary of $90,000. The mean has risen to $40,000, while the median remains at $30,000.\n",
    "\n",
    "This outlier makes the median a better indicator of typical salary than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d54ca7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 73764 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   user_id      73764 non-null  int64  \n",
      " 1   device_type  73764 non-null  object \n",
      " 2   age          73764 non-null  float64\n",
      " 3   time         61588 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 2.8+ MB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26236 entries, 1 to 99997\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   user_id      26236 non-null  int64  \n",
      " 1   device_type  26236 non-null  object \n",
      " 2   age          26236 non-null  float64\n",
      " 3   time         13823 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('DataSets/web_analytics_data.csv')\n",
    "\n",
    "age_avg = analytics_data['age'].mean()\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "desktop_data = analytics_data[analytics_data['device_type'] == 'desktop']\n",
    "mobile_data =  analytics_data[analytics_data['device_type'] == 'mobile']\n",
    "\n",
    "desktop_data.info()\n",
    "print()\n",
    "mobile_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "898320db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de escritorio promedio: 1741.87 segundos\n",
      "Tiempo móvil promedio: 41.16 segundos\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('DataSets/web_analytics_data.csv')\n",
    "\n",
    "age_avg = analytics_data['age'].mean()\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "desktop_data = analytics_data[analytics_data['device_type'] == 'desktop']\n",
    "mobile_data =  analytics_data[analytics_data['device_type'] == 'mobile']\n",
    "\n",
    "desktop_avg = desktop_data['time'].mean()\n",
    "mobile_avg = mobile_data['time'].mean()\n",
    "\n",
    "print(f\"Tiempo de escritorio promedio: {desktop_avg:.2f} segundos\")\n",
    "print(f\"Tiempo móvil promedio: {mobile_avg:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0dd7416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 73764 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   user_id      73764 non-null  int64  \n",
      " 1   device_type  73764 non-null  object \n",
      " 2   age          73764 non-null  float64\n",
      " 3   time         73764 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 2.8+ MB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26236 entries, 1 to 99997\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   user_id      26236 non-null  int64  \n",
      " 1   device_type  26236 non-null  object \n",
      " 2   age          26236 non-null  float64\n",
      " 3   time         26236 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "analytics_data = pd.read_csv('DataSets/web_analytics_data.csv')\n",
    "\n",
    "age_avg = analytics_data['age'].mean()\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "desktop_data = analytics_data[analytics_data['device_type'] == 'desktop']\n",
    "mobile_data =  analytics_data[analytics_data['device_type'] == 'mobile']\n",
    "\n",
    "desktop_avg = desktop_data['time'].mean()\n",
    "mobile_avg = mobile_data['time'].mean()\n",
    "\n",
    "desktop_data['time'] = desktop_data['time'].fillna(desktop_avg)\n",
    "mobile_data['time'] = mobile_data['time'].fillna(mobile_avg)\n",
    "\n",
    "# esto comprobará si tienes algún valor ausente\n",
    "desktop_data.info()\n",
    "print()\n",
    "mobile_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e8c131",
   "metadata": {},
   "source": [
    "##### __Excercise__\n",
    "\n",
    "In this activity, we'll define a DataFrame. Your work will consist of the following:\n",
    "\n",
    "- Filter the rows for the 'North' and 'South' regions.\n",
    "\n",
    "- Calculate the average income for each region.\n",
    "\n",
    "- Use info() to verify the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3dab6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de ingresos en 'North': 125.0\n",
      "Promedio de ingresos en 'South': 93.75\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, 0 to 8\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   user_id  5 non-null      int64  \n",
      " 1   region   5 non-null      object \n",
      " 2   age      4 non-null      float64\n",
      " 3   revenue  3 non-null      float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 200.0+ bytes\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, 1 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   user_id  5 non-null      int64  \n",
      " 1   region   5 non-null      object \n",
      " 2   age      4 non-null      float64\n",
      " 3   revenue  4 non-null      float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 200.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'user_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'region': ['North', 'South', 'North', 'South', 'North', 'South', 'North', 'South', 'North', 'South'],\n",
    "    'age': [25, 34, 45, None, 38, 50, None, 28, 42, 35],\n",
    "    'revenue': [120, 80, 130, 95, None, None, 125, 90, None, 110]\n",
    "}\n",
    "\n",
    "sales_data = pd.DataFrame(data)\n",
    "\n",
    "north_data = sales_data[sales_data['region'] == 'North']\n",
    "south_data = sales_data[sales_data['region'] == 'South']\n",
    "\n",
    "north_avg = north_data['revenue'].mean()\n",
    "south_avg = south_data['revenue'].mean()\n",
    "\n",
    "print(f\"Promedio de ingresos en 'North': {north_avg}\")\n",
    "print(f\"Promedio de ingresos en 'South': {south_avg}\")\n",
    "\n",
    "north_data.info()\n",
    "print()\n",
    "south_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5bc1d1",
   "metadata": {},
   "source": [
    "We'll continue working on the same case as in exercise 1. This time, using the same DataFrame, you'll use the average income for the 'North' region to fill in the missing values ​​in that region, and the same for the 'South' region. Additionally, display the averages calculated for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb47cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "\n",
    "\n",
    "data = {\n",
    "    'user_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'region': ['North', 'South', 'North', 'South', 'North', 'South', 'North', 'South', 'North', 'South'],\n",
    "    'age': [25, 34, 45, None, 38, 50, None, 28, 42, 35],\n",
    "    'revenue': [120, 80, 130, 95, None, None, 125, 90, None, 110]\n",
    "}\n",
    "\n",
    "# Convertir a DataFrame\n",
    "sales_data = pd.DataFrame(data)\n",
    "\n",
    "# Filtrar los datos por región\n",
    "north_data = sales_data[sales_data['region'] == 'North']\n",
    "south_data = sales_data[sales_data['region'] == 'South']\n",
    "\n",
    "# Calcular el promedio de ingresos por región\n",
    "north_avg = north_data['revenue'].mean()\n",
    "south_avg = south_data['revenue'].mean()\n",
    "\n",
    "# Imprimir los promedios calculados\n",
    "print(f\"Promedio de ingresos en 'North': {north_avg}\")\n",
    "print(f\"Promedio de ingresos en 'South': {south_avg}\")\n",
    "\n",
    "# Rellenar los valores ausentes con el promedio de ingresos por región\n",
    "north_data['revenue'] = north_data['revenue'].fillna(north_avg)\n",
    "south_data['revenue'] = south_data['revenue'].fillna(south_avg)\n",
    "\n",
    "# Comprobar si aún hay valores ausentes\n",
    "north_data.info()\n",
    "print()\n",
    "south_data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-Github_VENV-XjlEX2HA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
